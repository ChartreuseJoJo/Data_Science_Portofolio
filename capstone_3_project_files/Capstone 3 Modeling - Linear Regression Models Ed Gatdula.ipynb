{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone 3 - Modeling\n",
    "\n",
    "\n",
    "## Hypothesis:  Does inclusion of consumer confiden index (cci) improve model prediction score for sales?  How much does logrithmic transformation of several non-normal distributed features improve predictions?\n",
    "\n",
    "\n",
    "Procedure:\n",
    "\n",
    "Part I.\n",
    "\n",
    "Build and apply column transformer to Train Set-\n",
    "\n",
    "Nominal Categories: 'IsHoliday', 'Dept'\n",
    "\n",
    "Ordinal Categories: 'Week','Type'\n",
    "\n",
    "Standard Scaler for Numerical Features: 'Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment', 'Size','cci_value'\n",
    "\n",
    "\n",
    "Part II.  Obtain base model performance metrics without cci values.\n",
    "\n",
    "1. Fit following models without cci data:  Ordinary Least Squares(OLS), ElasticNet, Random Forest Regressor,\n",
    "XGBoost, HistGradientBoost.\n",
    "2. Cross validate to obtain coefficient of determination (R2), mean squared error (MSE), and mean average error (MAE) for each model. \n",
    "\n",
    "Part III.  Using models from Part I, obtain performance metrics with cci values.\n",
    "1. Build and test models from Part I with cci data.\n",
    "2.  Record coefficient of determination (R2), mean squared error (MSE), and mean average error (MAE) for each model. \n",
    "3.  Cross validate to obtain R2, MSE, and MAE scores.\n",
    "4.  Compare R2, MSE, and MAE scores between Parts II and III.\n",
    "\n",
    "Part IV.  Apply logrithmic function to following features: 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown3',\n",
    "'MarkDown4', 'MarkDown5'\n",
    "1.  Create new features by applying logrithmic function to following features: 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown3', 'MarkDown4', 'MarkDown5'.\n",
    "2.  Drop original \"MarkDown1\", \"MarkDown2\", \"MarkDown3\", \"MarkDown4\", and \"MarkDown5\" features from Training data.\n",
    "3.  Fit HistGradientBoost and Random Forest models to training data.\n",
    "4.  Cross validate to obtain R2, MSE, MAE scores.\n",
    "5.  Compare R2, MSE MAE scores between II and IV.\n",
    "\n",
    "Results:\n",
    "\n",
    "See Capstone 3 Modeling - Results Plots.ipynb\n",
    "\n",
    "\n",
    "Conclusion:\n",
    "\n",
    "See Capstone 3 Modeling - Results Plots.ipynb\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T18:56:17.572924Z",
     "start_time": "2021-11-01T18:56:17.567510Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T18:56:24.531028Z",
     "start_time": "2021-11-01T18:56:24.029066Z"
    }
   },
   "outputs": [],
   "source": [
    "# sklearn libraries\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV, RandomizedSearchCV, TimeSeriesSplit\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "\n",
    "#Model Metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import xgboost as xgb \n",
    "\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T16:41:37.102579Z",
     "start_time": "2021-10-28T16:41:36.956851Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capstone 3 Data Wrangling Ed Gatdula.ipynb\r\n",
      "Capstone 3 EDA Ed Gatdula.ipynb\r\n",
      "Capstone 3 Modeling - Ensemble Regression Models.ipynb\r\n",
      "Capstone 3 Modeling - Linear Regression Models Ed Gatdula.ipynb\r\n",
      "Capstone 3 Modeling - Regression Model Compilations.ipynb\r\n",
      "Capstone 3 Modeling - TimeSeriesSplit Version.ipynb\r\n",
      "Feature Union Worksheet.ipynb\r\n",
      "\u001b[34mKaggle Submissions\u001b[m\u001b[m\r\n",
      "Log Transform MarkDown Features.ipynb\r\n",
      "\u001b[34mMisc Worksheet\u001b[m\u001b[m\r\n",
      "\u001b[34mcapstone 3 project data\u001b[m\u001b[m\r\n",
      "capstone_3\r\n",
      "capstone_3_test_data\r\n",
      "capstone_3_train_data\r\n",
      "capstone_3_wrnglng_results\r\n",
      "kaggle_submission5_randomforest_randomsearchcv\r\n",
      "\u001b[34mreport_images\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T18:56:42.771956Z",
     "start_time": "2021-11-01T18:56:42.579320Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_test shape: (115064, 18)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 115064 entries, 0 to 115063\n",
      "Data columns (total 18 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   Date          115064 non-null  object \n",
      " 1   Store         115064 non-null  int64  \n",
      " 2   Dept          115064 non-null  int64  \n",
      " 3   IsHoliday     115064 non-null  int64  \n",
      " 4   Temperature   115064 non-null  float64\n",
      " 5   Fuel_Price    115064 non-null  float64\n",
      " 6   MarkDown1     115064 non-null  float64\n",
      " 7   MarkDown2     115064 non-null  float64\n",
      " 8   MarkDown3     115064 non-null  float64\n",
      " 9   MarkDown4     115064 non-null  float64\n",
      " 10  MarkDown5     115064 non-null  float64\n",
      " 11  CPI           115064 non-null  float64\n",
      " 12  Unemployment  115064 non-null  float64\n",
      " 13  isocalendar   115064 non-null  object \n",
      " 14  Week          115064 non-null  int64  \n",
      " 15  Type          115064 non-null  object \n",
      " 16  Size          115064 non-null  int64  \n",
      " 17  cci_value     115064 non-null  float64\n",
      "dtypes: float64(10), int64(5), object(3)\n",
      "memory usage: 15.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Store</th>\n",
       "      <th>Dept</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>MarkDown1</th>\n",
       "      <th>MarkDown2</th>\n",
       "      <th>MarkDown3</th>\n",
       "      <th>MarkDown4</th>\n",
       "      <th>MarkDown5</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>isocalendar</th>\n",
       "      <th>Week</th>\n",
       "      <th>Type</th>\n",
       "      <th>Size</th>\n",
       "      <th>cci_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-11-02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55.32</td>\n",
       "      <td>3.386</td>\n",
       "      <td>6766.44</td>\n",
       "      <td>5147.7</td>\n",
       "      <td>50.82</td>\n",
       "      <td>3639.9</td>\n",
       "      <td>2737.42</td>\n",
       "      <td>223.462779</td>\n",
       "      <td>6.573</td>\n",
       "      <td>(2012, 44)</td>\n",
       "      <td>44</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>99.00362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-11-02</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>55.32</td>\n",
       "      <td>3.386</td>\n",
       "      <td>6766.44</td>\n",
       "      <td>5147.7</td>\n",
       "      <td>50.82</td>\n",
       "      <td>3639.9</td>\n",
       "      <td>2737.42</td>\n",
       "      <td>223.462779</td>\n",
       "      <td>6.573</td>\n",
       "      <td>(2012, 44)</td>\n",
       "      <td>44</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>99.00362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-11-02</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>55.32</td>\n",
       "      <td>3.386</td>\n",
       "      <td>6766.44</td>\n",
       "      <td>5147.7</td>\n",
       "      <td>50.82</td>\n",
       "      <td>3639.9</td>\n",
       "      <td>2737.42</td>\n",
       "      <td>223.462779</td>\n",
       "      <td>6.573</td>\n",
       "      <td>(2012, 44)</td>\n",
       "      <td>44</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>99.00362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-11-02</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>55.32</td>\n",
       "      <td>3.386</td>\n",
       "      <td>6766.44</td>\n",
       "      <td>5147.7</td>\n",
       "      <td>50.82</td>\n",
       "      <td>3639.9</td>\n",
       "      <td>2737.42</td>\n",
       "      <td>223.462779</td>\n",
       "      <td>6.573</td>\n",
       "      <td>(2012, 44)</td>\n",
       "      <td>44</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>99.00362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-11-02</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>55.32</td>\n",
       "      <td>3.386</td>\n",
       "      <td>6766.44</td>\n",
       "      <td>5147.7</td>\n",
       "      <td>50.82</td>\n",
       "      <td>3639.9</td>\n",
       "      <td>2737.42</td>\n",
       "      <td>223.462779</td>\n",
       "      <td>6.573</td>\n",
       "      <td>(2012, 44)</td>\n",
       "      <td>44</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>99.00362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Store  Dept  IsHoliday  Temperature  Fuel_Price  MarkDown1  \\\n",
       "0  2012-11-02      1     1          0        55.32       3.386    6766.44   \n",
       "1  2012-11-02      1     2          0        55.32       3.386    6766.44   \n",
       "2  2012-11-02      1     3          0        55.32       3.386    6766.44   \n",
       "3  2012-11-02      1     4          0        55.32       3.386    6766.44   \n",
       "4  2012-11-02      1     5          0        55.32       3.386    6766.44   \n",
       "\n",
       "   MarkDown2  MarkDown3  MarkDown4  MarkDown5         CPI  Unemployment  \\\n",
       "0     5147.7      50.82     3639.9    2737.42  223.462779         6.573   \n",
       "1     5147.7      50.82     3639.9    2737.42  223.462779         6.573   \n",
       "2     5147.7      50.82     3639.9    2737.42  223.462779         6.573   \n",
       "3     5147.7      50.82     3639.9    2737.42  223.462779         6.573   \n",
       "4     5147.7      50.82     3639.9    2737.42  223.462779         6.573   \n",
       "\n",
       "  isocalendar  Week Type    Size  cci_value  \n",
       "0  (2012, 44)    44    A  151315   99.00362  \n",
       "1  (2012, 44)    44    A  151315   99.00362  \n",
       "2  (2012, 44)    44    A  151315   99.00362  \n",
       "3  (2012, 44)    44    A  151315   99.00362  \n",
       "4  (2012, 44)    44    A  151315   99.00362  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test set for kaggle prediction\n",
    "\n",
    "df_test = pd.read_csv('./capstone_3_test_data')\n",
    "print('df_test shape: {}\\n'.format(df_test.shape))\n",
    "df_test.info()\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Set: \n",
    "\n",
    "Using OrdinalEncoder, OneHotEncoder, StandardScaler to:\n",
    "\n",
    "1. prepare data for model use\n",
    "2. prepare columntransformer in pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T18:58:24.498020Z",
     "start_time": "2021-11-01T18:58:23.990337Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train shape: (421570, 19)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 421570 entries, 0 to 421569\n",
      "Data columns (total 19 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   Date          421570 non-null  object \n",
      " 1   Store         421570 non-null  int64  \n",
      " 2   Dept          421570 non-null  int64  \n",
      " 3   Weekly_Sales  421570 non-null  float64\n",
      " 4   IsHoliday     421570 non-null  int64  \n",
      " 5   Temperature   421570 non-null  float64\n",
      " 6   Fuel_Price    421570 non-null  float64\n",
      " 7   MarkDown1     421570 non-null  float64\n",
      " 8   MarkDown2     421570 non-null  float64\n",
      " 9   MarkDown3     421570 non-null  float64\n",
      " 10  MarkDown4     421570 non-null  float64\n",
      " 11  MarkDown5     421570 non-null  float64\n",
      " 12  CPI           421570 non-null  float64\n",
      " 13  Unemployment  421570 non-null  float64\n",
      " 14  isocalendar   421570 non-null  object \n",
      " 15  Week          421570 non-null  int64  \n",
      " 16  Type          421570 non-null  object \n",
      " 17  Size          421570 non-null  int64  \n",
      " 18  cci_value     421570 non-null  float64\n",
      "dtypes: float64(11), int64(5), object(3)\n",
      "memory usage: 61.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Store</th>\n",
       "      <th>Dept</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>MarkDown1</th>\n",
       "      <th>MarkDown2</th>\n",
       "      <th>MarkDown3</th>\n",
       "      <th>MarkDown4</th>\n",
       "      <th>MarkDown5</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>isocalendar</th>\n",
       "      <th>Week</th>\n",
       "      <th>Type</th>\n",
       "      <th>Size</th>\n",
       "      <th>cci_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24924.50</td>\n",
       "      <td>0</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>(2010, 5)</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>98.22324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50605.27</td>\n",
       "      <td>0</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>(2010, 5)</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>98.22324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>13740.12</td>\n",
       "      <td>0</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>(2010, 5)</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>98.22324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>39954.04</td>\n",
       "      <td>0</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>(2010, 5)</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>98.22324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>32229.38</td>\n",
       "      <td>0</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>(2010, 5)</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>98.22324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Store  Dept  Weekly_Sales  IsHoliday  Temperature  Fuel_Price  \\\n",
       "0  2010-02-05      1     1      24924.50          0        42.31       2.572   \n",
       "1  2010-02-05      1     2      50605.27          0        42.31       2.572   \n",
       "2  2010-02-05      1     3      13740.12          0        42.31       2.572   \n",
       "3  2010-02-05      1     4      39954.04          0        42.31       2.572   \n",
       "4  2010-02-05      1     5      32229.38          0        42.31       2.572   \n",
       "\n",
       "   MarkDown1  MarkDown2  MarkDown3  MarkDown4  MarkDown5         CPI  \\\n",
       "0        0.0        0.0        0.0        0.0        0.0  211.096358   \n",
       "1        0.0        0.0        0.0        0.0        0.0  211.096358   \n",
       "2        0.0        0.0        0.0        0.0        0.0  211.096358   \n",
       "3        0.0        0.0        0.0        0.0        0.0  211.096358   \n",
       "4        0.0        0.0        0.0        0.0        0.0  211.096358   \n",
       "\n",
       "   Unemployment isocalendar  Week Type    Size  cci_value  \n",
       "0         8.106   (2010, 5)     5    A  151315   98.22324  \n",
       "1         8.106   (2010, 5)     5    A  151315   98.22324  \n",
       "2         8.106   (2010, 5)     5    A  151315   98.22324  \n",
       "3         8.106   (2010, 5)     5    A  151315   98.22324  \n",
       "4         8.106   (2010, 5)     5    A  151315   98.22324  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training data\n",
    "df_train = pd.read_csv('./capstone_3_train_data.csv')\n",
    "print('df_train shape: {}\\n'.format(df_train.shape))\n",
    "df_train.info()\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T18:59:26.261333Z",
     "start_time": "2021-11-01T18:59:26.256064Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train features: 19\n",
      "['Date', 'Store', 'Dept', 'Weekly_Sales', 'IsHoliday', 'Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment', 'isocalendar', 'Week', 'Type', 'Size', 'cci_value']\n"
     ]
    }
   ],
   "source": [
    "train_features = df_train.columns.to_list()\n",
    "print(\"Number of train features: {}\".format(len(train_features)))\n",
    "print(train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Transformer Setup\n",
    "\n",
    "\n",
    "two column_transform objects:\n",
    "\n",
    "###  column_transform_no_cci\n",
    "\n",
    "IMPORTANT! drop 'cci_value' from column transformer setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T16:41:37.822245Z",
     "start_time": "2021-10-28T16:41:37.819947Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(421570, 19)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T19:19:51.559860Z",
     "start_time": "2021-11-01T19:19:50.439487Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(sparse_threshold=0,\n",
       "                  transformers=[('standardscaler', StandardScaler(),\n",
       "                                 ['Temperature', 'Fuel_Price', 'MarkDown1',\n",
       "                                  'MarkDown2', 'MarkDown3', 'MarkDown4',\n",
       "                                  'MarkDown5', 'CPI', 'Unemployment', 'Size']),\n",
       "                                ('onehotencoder',\n",
       "                                 OneHotEncoder(handle_unknown='ignore'),\n",
       "                                 ['IsHoliday', 'Dept', 'Store']),\n",
       "                                ('ordinalencoder', OrdinalEncoder(),\n",
       "                                 ['Week', 'Type', 'isocalendar'])])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# column_transform_no_cci\n",
    "# 'Date', 'Store', 'Dept', 'Weekly_Sales', 'IsHoliday', 'Temperature', 'Fuel_Price', 'MarkDown1',\n",
    "# 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment', 'isocalendar', 'Week',\n",
    "# 'Type', 'Size', 'cci_value'\n",
    "\n",
    "# 3 Nominal Categories: 'IsHoliday', 'Dept','Store'\n",
    "\n",
    "ohe=OneHotEncoder(handle_unknown='ignore')\n",
    "ohe.fit_transform(df_train[[\"IsHoliday\",'Dept','Store']])\n",
    "ohe.categories_\n",
    "\n",
    "# 3 Ordinal Categories: 'Week', 'Type', 'isocalendar'\n",
    "oe = OrdinalEncoder()\n",
    "oe.fit_transform(df_train[['Week','Type', 'isocalendar']])\n",
    "oe.categories_\n",
    "\n",
    "# 10 Standard Scaler for Numerical Feature\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(df_train[['Temperature', 'Fuel_Price', 'MarkDown1',\n",
    "                                  'MarkDown2', 'MarkDown3', 'MarkDown4',\n",
    "                                  'MarkDown5', 'CPI', 'Unemployment', 'Size',\n",
    "                              #    'cci_value'\n",
    "                              ]])\n",
    "\n",
    "# Instantiate make_column_transformer using standard scaler, onehotencoder, ordinalencoder\n",
    "\n",
    "column_transform_no_cci = make_column_transformer((scaler,['Temperature', 'Fuel_Price','MarkDown1',\n",
    "                                                              'MarkDown2', 'MarkDown3', 'MarkDown4',\n",
    "                                                              'MarkDown5', 'CPI', 'Unemployment', 'Size',\n",
    "                                                          #    'cci_value'\n",
    "                                                          ]),\n",
    "                                           (ohe,['IsHoliday','Dept','Store']), \n",
    "                                           (oe,['Week','Type','isocalendar']),sparse_threshold=0)\n",
    "\n",
    "#fit_transform make_column_transformer object\n",
    "column_transform_no_cci.fit(df_train.drop(columns = ['Date','Weekly_Sales','cci_value']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  column_transform_cci\n",
    "\n",
    "IMPORTANT:  Retains Consumer Confidence Index (cci) values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T19:17:50.462335Z",
     "start_time": "2021-11-01T19:17:49.301463Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(sparse_threshold=0,\n",
       "                  transformers=[('standardscaler', StandardScaler(),\n",
       "                                 ['Temperature', 'Fuel_Price', 'MarkDown1',\n",
       "                                  'MarkDown2', 'MarkDown3', 'MarkDown4',\n",
       "                                  'MarkDown5', 'CPI', 'Unemployment', 'Size',\n",
       "                                  'cci_value']),\n",
       "                                ('onehotencoder',\n",
       "                                 OneHotEncoder(handle_unknown='ignore'),\n",
       "                                 ['IsHoliday', 'Dept', 'Store']),\n",
       "                                ('ordinalencoder', OrdinalEncoder(),\n",
       "                                 ['Week', 'Type', 'isocalendar'])])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# column_transform_cci\n",
    "# 'Date', 'Store', 'Dept', 'Weekly_Sales', 'IsHoliday', 'Temperature', 'Fuel_Price', 'MarkDown1',\n",
    "# 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment', 'isocalendar', 'Week',\n",
    "# 'Type', 'Size', 'cci_value'\n",
    "\n",
    "# 3 Nominal Categories: 'IsHoliday', 'Dept','Store'\n",
    "\n",
    "ohe=OneHotEncoder(handle_unknown='ignore')\n",
    "ohe.fit_transform(df_train[[\"IsHoliday\",'Dept','Store']])\n",
    "ohe.categories_\n",
    "\n",
    "# 3 Ordinal Categories: 'Week', 'Type', 'isocalendar'\n",
    "oe = OrdinalEncoder()\n",
    "oe.fit_transform(df_train[['Week','Type', 'isocalendar']])\n",
    "oe.categories_\n",
    "\n",
    "# 11 Standard Scaler for Numerical Feature (includes 'cci_value' feature)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(df_train[['Temperature', 'Fuel_Price', 'MarkDown1',\n",
    "                                  'MarkDown2', 'MarkDown3', 'MarkDown4',\n",
    "                                  'MarkDown5', 'CPI', 'Unemployment', 'Size',\n",
    "                                  'cci_value'\n",
    "                              ]])\n",
    "\n",
    "# Instantiate make_column_transformer using standard scaler, onehotencoder, ordinalencoder\n",
    "\n",
    "column_transform_cci = make_column_transformer((scaler,['Temperature', 'Fuel_Price','MarkDown1',\n",
    "                                                              'MarkDown2', 'MarkDown3', 'MarkDown4',\n",
    "                                                              'MarkDown5', 'CPI', 'Unemployment', 'Size',\n",
    "                                                              'cci_value'\n",
    "                                                          ]),\n",
    "                                           (ohe,['IsHoliday','Dept','Store']), \n",
    "                                           (oe,['Week','Type','isocalendar']),sparse_threshold=0)\n",
    "\n",
    "#fit_transform make_column_transformer object\n",
    "column_transform_cci.fit(df_train.drop(columns = ['Date','Weekly_Sales']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression \n",
    "\n",
    "note:  all cross validation scores recorded in dataframe named df_scores\n",
    "\n",
    "## Linear Regression (no cci values) - TimeSeriesSplit Cross-Validation Using For-Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T19:05:23.677655Z",
     "start_time": "2021-11-01T19:05:23.673952Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Store', 'Dept', 'Weekly_Sales', 'IsHoliday', 'Temperature',\n",
       "       'Fuel_Price', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4',\n",
       "       'MarkDown5', 'CPI', 'Unemployment', 'isocalendar', 'Week', 'Type',\n",
       "       'Size', 'cci_value'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T19:13:24.644660Z",
     "start_time": "2021-11-01T19:13:19.022262Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE scores: [-5.87771188e+27 -2.55857059e+26 -2.32052518e+22 -2.60963165e+26\n",
      " -9.58236393e+25]\n",
      "R2 scores: [-8.08840292e+18 -5.39585175e+17 -4.85127160e+13 -7.70030055e+17\n",
      " -2.58427474e+17]\n",
      "MAE scores: [-6.31688390e+13 -1.35981239e+13 -1.19603516e+11 -9.69012159e+12\n",
      " -8.79034065e+12]\n"
     ]
    }
   ],
   "source": [
    "# cross validate base linear regression model, no cci_value\n",
    "\n",
    "Y = df_train.Weekly_Sales\n",
    "X = df_train.drop(columns = ['Date','Weekly_Sales', 'cci_value'])\n",
    "\n",
    "#fit column transformer using entire train set\n",
    "\n",
    "tranform_no_cci = column_transform_no_cci.fit(X)\n",
    "\n",
    "cv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# transform column transformer on each time series split\n",
    "lr_no_cci_scores = cross_validate(LinearRegression(), column_transform_no_cci.transform(X), Y, cv=cv,\n",
    "                        scoring=('r2', 'neg_mean_squared_error', 'neg_mean_absolute_error'))\n",
    "\n",
    "print(\"MSE scores: {}\".format(lr_no_cci_scores['test_neg_mean_squared_error']))\n",
    "print(\"R2 scores: {}\".format(lr_no_cci_scores['test_r2']))\n",
    "print(\"MAE scores: {}\".format(lr_no_cci_scores['test_neg_mean_absolute_error']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T19:13:58.317321Z",
     "start_time": "2021-11-01T19:13:58.305624Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_r2': 1.9312988279932575e+18,\n",
       " 'test_neg_mean_squared_error': 1.2980757890467114e+27,\n",
       " 'test_neg_mean_absolute_error': 19073405730295.04}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write a function that returns average of cross validation scores\n",
    "list = {}\n",
    "\n",
    "def scores(name):\n",
    "    keys = ['test_r2', 'test_neg_mean_squared_error',\n",
    "            'test_neg_mean_absolute_error']\n",
    "    for item in keys:\n",
    "        z = list.update({item: np.round(np.mean(np.abs(name[item])), 2)})\n",
    "    return list\n",
    "\n",
    "\n",
    "scores(lr_no_cci_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T19:14:20.169822Z",
     "start_time": "2021-11-01T19:14:20.159788Z"
    }
   },
   "outputs": [],
   "source": [
    "# create dataframe to store model performance metrics\n",
    "df_summary = pd.DataFrame(columns = ['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T19:14:26.601427Z",
     "start_time": "2021-11-01T19:14:26.597473Z"
    }
   },
   "outputs": [],
   "source": [
    "# function to write model name and results to a dict.  dict be used to create df_summary entry\n",
    "\n",
    "def write(description, cv_scores):\n",
    "    dict1 = {'model description':description}\n",
    "    dict2 = scores(cv_scores)\n",
    "    dict2.update(dict1)\n",
    "    return(dict2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T19:14:29.745986Z",
     "start_time": "2021-11-01T19:14:29.719424Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>model description</th>\n",
       "      <th>test_neg_mean_absolute_error</th>\n",
       "      <th>test_neg_mean_squared_error</th>\n",
       "      <th>test_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>lr base no cci</td>\n",
       "      <td>1.907341e+13</td>\n",
       "      <td>1.298076e+27</td>\n",
       "      <td>1.931299e+18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name model description  test_neg_mean_absolute_error  \\\n",
       "0   NaN    lr base no cci                  1.907341e+13   \n",
       "\n",
       "   test_neg_mean_squared_error       test_r2  \n",
       "0                 1.298076e+27  1.931299e+18  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary = df_summary.append(write('lr base no cci', lr_no_cci_scores), ignore_index=True)\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression (cci values) - TimeSeriesSplit Cross-Validation Using For-Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T19:18:33.709154Z",
     "start_time": "2021-11-01T19:18:28.215542Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE scores: [-3.39916478e+25 -1.14079090e+26 -1.47648565e+23 -4.14002926e+25\n",
      " -5.29881750e+23]\n",
      "R2 scores: [-4.67763901e+16 -2.40585060e+17 -3.08672923e+14 -1.22160802e+17\n",
      " -1.42904197e+15]\n",
      "MAE scores: [-5.40063577e+12 -9.09096992e+12 -3.37511199e+11 -5.32306622e+12\n",
      " -6.62666847e+11]\n"
     ]
    }
   ],
   "source": [
    "# cross validate base linear regression model with cci_value\n",
    "\n",
    "cv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# cross validate base linear regression model, no cci_value\n",
    "\n",
    "Y = df_train.Weekly_Sales\n",
    "X = df_train.drop(columns = ['Date','Weekly_Sales'])\n",
    "\n",
    "#fit column transformer using entire train set\n",
    "\n",
    "tranform_no_cci = column_transform_cci.fit(X)\n",
    "\n",
    "# cross validate \n",
    "# transform column transformer on each time series split\n",
    "\n",
    "lr_cci_scores = cross_validate(LinearRegression(), column_transform_cci.transform(X), Y, cv=cv,\n",
    "                        scoring=('r2', 'neg_mean_squared_error', 'neg_mean_absolute_error'))\n",
    "\n",
    "print(\"MSE scores: {}\".format(lr_cci_scores['test_neg_mean_squared_error']))\n",
    "print(\"R2 scores: {}\".format(lr_cci_scores['test_r2']))\n",
    "print(\"MAE scores: {}\".format(lr_cci_scores['test_neg_mean_absolute_error']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T19:18:37.421211Z",
     "start_time": "2021-11-01T19:18:37.407685Z"
    }
   },
   "outputs": [],
   "source": [
    "# appending metrics to df_summary\n",
    "scores(lr_cci_scores)\n",
    "\n",
    "score_dict = write('lr cci', lr_cci_scores)\n",
    "\n",
    "df_summary = df_summary.append(score_dict, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T19:18:41.759209Z",
     "start_time": "2021-11-01T19:18:41.743315Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>model description</th>\n",
       "      <th>test_neg_mean_absolute_error</th>\n",
       "      <th>test_neg_mean_squared_error</th>\n",
       "      <th>test_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>lr base no cci</td>\n",
       "      <td>1.907341e+13</td>\n",
       "      <td>1.298076e+27</td>\n",
       "      <td>1.931299e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>lr cci</td>\n",
       "      <td>4.162970e+12</td>\n",
       "      <td>3.802971e+25</td>\n",
       "      <td>8.225199e+16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name model description  test_neg_mean_absolute_error  \\\n",
       "0   NaN    lr base no cci                  1.907341e+13   \n",
       "1   NaN            lr cci                  4.162970e+12   \n",
       "\n",
       "   test_neg_mean_squared_error       test_r2  \n",
       "0                 1.298076e+27  1.931299e+18  \n",
       "1                 3.802971e+25  8.225199e+16  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression (no cci_value) - GridSearchCV, PCA, TimeSeriesSplit \n",
    "\n",
    "Results:  PCA does not improve Linear Regression Root Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T19:21:52.535053Z",
     "start_time": "2021-11-01T19:21:16.029066Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "             estimator=Pipeline(steps=[('reducer', PCA()),\n",
       "                                       ('linear',\n",
       "                                        LinearRegression(normalize=True))]),\n",
       "             param_grid={'reducer__n_components': [1, 2, 3, 4, 5, 6, 7]},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define steps\n",
    "\n",
    "# instantiate pipeline object\n",
    "\n",
    "steps = [('reducer', PCA()),\n",
    "        ('linear', LinearRegression(normalize=True))]\n",
    "\n",
    "pipe = Pipeline(steps)\n",
    "\n",
    "# define gridsearch parameters dict\n",
    "\n",
    "param_grid = {'reducer__n_components':[1,2,3,4,5,6,7]}\n",
    "\n",
    "# split data into test train split\n",
    "Y = df_train['Weekly_Sales']\n",
    "X = df_train.drop(columns = ['Date','cci_value','Weekly_Sales'])\n",
    "Z = column_transform_no_cci.fit(X)\n",
    "\n",
    "# instantiate GridSearchCV object using pipeline, parameters dict\n",
    "cv = TimeSeriesSplit(n_splits=5)\n",
    "lr_grid_search = GridSearchCV(pipe, param_grid ,cv=cv, return_train_score = True)\n",
    "\n",
    "# grid search fit\n",
    "lr_grid_search.fit(Z.transform(X),Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T19:23:24.577714Z",
     "start_time": "2021-11-01T19:22:02.198980Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.99638840e+08 -4.58622596e+08 -4.87113874e+08 -3.44185271e+08\n",
      " -3.64175858e+08]\n",
      "[ 0.03721704  0.03279607 -0.01835642 -0.01559545  0.01785146]\n",
      "[-18091.56783053 -14953.6799979  -16395.66055545 -13802.56299493\n",
      " -12969.80484779]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>model description</th>\n",
       "      <th>test_neg_mean_absolute_error</th>\n",
       "      <th>test_neg_mean_squared_error</th>\n",
       "      <th>test_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>lr base no cci</td>\n",
       "      <td>1.907341e+13</td>\n",
       "      <td>1.298076e+27</td>\n",
       "      <td>1.931299e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>lr cci</td>\n",
       "      <td>4.162970e+12</td>\n",
       "      <td>3.802971e+25</td>\n",
       "      <td>8.225199e+16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>lr gridsearch</td>\n",
       "      <td>1.524266e+04</td>\n",
       "      <td>4.707473e+08</td>\n",
       "      <td>2.000000e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name model description  test_neg_mean_absolute_error  \\\n",
       "0   NaN    lr base no cci                  1.907341e+13   \n",
       "1   NaN            lr cci                  4.162970e+12   \n",
       "2   NaN     lr gridsearch                  1.524266e+04   \n",
       "\n",
       "   test_neg_mean_squared_error       test_r2  \n",
       "0                 1.298076e+27  1.931299e+18  \n",
       "1                 3.802971e+25  8.225199e+16  \n",
       "2                 4.707473e+08  2.000000e-02  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross validate gridsearchcv model\n",
    "# fit column transformer using entire train set\n",
    "Y = df_train['Weekly_Sales']\n",
    "X = df_train.drop(columns = ['Date','cci_value','Weekly_Sales'])\n",
    "Z = column_transform_no_cci.fit(df_train.drop(columns = ['Date','cci_value','Weekly_Sales']))\n",
    "\n",
    "cv = TimeSeriesSplit(n_splits=5)\n",
    "lr_gridsearch_scores = cross_validate(lr_grid_search,\n",
    "                                      Z.transform(X), Y, cv=cv,\n",
    "                        scoring=('r2', 'neg_mean_squared_error', 'neg_mean_absolute_error'))\n",
    "print(lr_gridsearch_scores['test_neg_mean_squared_error'])\n",
    "print(lr_gridsearch_scores['test_r2'])\n",
    "print(lr_gridsearch_scores['test_neg_mean_absolute_error'])\n",
    "\n",
    "# appending metrics to df_summary\n",
    "scores(lr_gridsearch_scores)\n",
    "\n",
    "score_dict=write('lr gridsearch', lr_gridsearch_scores)\n",
    "\n",
    "df_summary=df_summary.append(score_dict, ignore_index=True)\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ElasticNet - GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet (no cci_value) - Manual CV Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T19:24:34.397790Z",
     "start_time": "2021-11-01T19:24:29.685532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE scores: [-6.79612232e+08 -4.39867174e+08 -4.58792047e+08 -3.22303939e+08\n",
      " -3.45738933e+08]\n",
      "R2 scores: [0.06477594 0.07234998 0.04085297 0.0489703  0.06757414]\n",
      "MAE scores: [-17510.12188566 -14594.33634497 -15757.47190423 -13029.54128439\n",
      " -13057.43660696]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# split data into test train split\n",
    "# cross validate base regression model, no cci_value\n",
    "\n",
    "cv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "Y = df_train['Weekly_Sales']\n",
    "X = df_train.drop(columns = ['Date','cci_value','Weekly_Sales'])\n",
    "Z = column_transform_no_cci.fit(df_train.drop(columns = ['Date','cci_value','Weekly_Sales']))\n",
    "\n",
    "elastic_no_cci_scores = cross_validate(ElasticNet(), Z.transform(X), Y, cv=cv,\n",
    "                        scoring=('r2', 'neg_mean_squared_error', 'neg_mean_absolute_error'))\n",
    "\n",
    "print(\"MSE scores: {}\".format(elastic_no_cci_scores['test_neg_mean_squared_error']))\n",
    "print(\"R2 scores: {}\".format(elastic_no_cci_scores['test_r2']))\n",
    "print(\"MAE scores: {}\".format(elastic_no_cci_scores['test_neg_mean_absolute_error']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T19:24:40.669933Z",
     "start_time": "2021-11-01T19:24:40.642287Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>model description</th>\n",
       "      <th>test_neg_mean_absolute_error</th>\n",
       "      <th>test_neg_mean_squared_error</th>\n",
       "      <th>test_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>lr base no cci</td>\n",
       "      <td>1.907341e+13</td>\n",
       "      <td>1.298076e+27</td>\n",
       "      <td>1.931299e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>lr cci</td>\n",
       "      <td>4.162970e+12</td>\n",
       "      <td>3.802971e+25</td>\n",
       "      <td>8.225199e+16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>lr gridsearch</td>\n",
       "      <td>1.524266e+04</td>\n",
       "      <td>4.707473e+08</td>\n",
       "      <td>2.000000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>elasticnet_base</td>\n",
       "      <td>1.478978e+04</td>\n",
       "      <td>4.492629e+08</td>\n",
       "      <td>6.000000e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name model description  test_neg_mean_absolute_error  \\\n",
       "0   NaN    lr base no cci                  1.907341e+13   \n",
       "1   NaN            lr cci                  4.162970e+12   \n",
       "2   NaN     lr gridsearch                  1.524266e+04   \n",
       "3   NaN   elasticnet_base                  1.478978e+04   \n",
       "\n",
       "   test_neg_mean_squared_error       test_r2  \n",
       "0                 1.298076e+27  1.931299e+18  \n",
       "1                 3.802971e+25  8.225199e+16  \n",
       "2                 4.707473e+08  2.000000e-02  \n",
       "3                 4.492629e+08  6.000000e-02  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# appending metrics to df_summary\n",
    "scores(elastic_no_cci_scores)\n",
    "\n",
    "score_dict=write('elasticnet_base', elastic_no_cci_scores)\n",
    "\n",
    "df_summary=df_summary.append(score_dict, ignore_index=True)\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet (cci_value)  -  TimeSeriesSplit Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T19:25:16.674829Z",
     "start_time": "2021-11-01T19:25:12.024732Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE scores: [-6.79524663e+08 -4.39791444e+08 -4.58813557e+08 -3.22290848e+08\n",
      " -3.45691994e+08]\n",
      "R2 scores: [0.06489645 0.07250969 0.040808   0.04900893 0.06770073]\n",
      "MAE scores: [-17512.47755491 -14590.81143557 -15758.00551711 -13028.20248363\n",
      " -13058.13549329]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>model description</th>\n",
       "      <th>test_neg_mean_absolute_error</th>\n",
       "      <th>test_neg_mean_squared_error</th>\n",
       "      <th>test_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>lr base no cci</td>\n",
       "      <td>1.907341e+13</td>\n",
       "      <td>1.298076e+27</td>\n",
       "      <td>1.931299e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>lr cci</td>\n",
       "      <td>4.162970e+12</td>\n",
       "      <td>3.802971e+25</td>\n",
       "      <td>8.225199e+16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>lr gridsearch</td>\n",
       "      <td>1.524266e+04</td>\n",
       "      <td>4.707473e+08</td>\n",
       "      <td>2.000000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>elasticnet_base</td>\n",
       "      <td>1.478978e+04</td>\n",
       "      <td>4.492629e+08</td>\n",
       "      <td>6.000000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>elasticnet_cci</td>\n",
       "      <td>1.478953e+04</td>\n",
       "      <td>4.492225e+08</td>\n",
       "      <td>6.000000e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name model description  test_neg_mean_absolute_error  \\\n",
       "0   NaN    lr base no cci                  1.907341e+13   \n",
       "1   NaN            lr cci                  4.162970e+12   \n",
       "2   NaN     lr gridsearch                  1.524266e+04   \n",
       "3   NaN   elasticnet_base                  1.478978e+04   \n",
       "4   NaN    elasticnet_cci                  1.478953e+04   \n",
       "\n",
       "   test_neg_mean_squared_error       test_r2  \n",
       "0                 1.298076e+27  1.931299e+18  \n",
       "1                 3.802971e+25  8.225199e+16  \n",
       "2                 4.707473e+08  2.000000e-02  \n",
       "3                 4.492629e+08  6.000000e-02  \n",
       "4                 4.492225e+08  6.000000e-02  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split data into test train split\n",
    "# cross validate base regression model, no cci_value\n",
    "\n",
    "cv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "Y = df_train['Weekly_Sales']\n",
    "X = df_train.drop(columns = ['Date','Weekly_Sales'])\n",
    "Z = column_transform_cci.fit(X)\n",
    "\n",
    "elastic_cci_scores = cross_validate(ElasticNet(), Z.transform(X), Y, cv=cv,\n",
    "                        scoring=('r2', 'neg_mean_squared_error', 'neg_mean_absolute_error'))\n",
    "\n",
    "print(\"MSE scores: {}\".format(elastic_cci_scores['test_neg_mean_squared_error']))\n",
    "print(\"R2 scores: {}\".format(elastic_cci_scores['test_r2']))\n",
    "print(\"MAE scores: {}\".format(elastic_cci_scores['test_neg_mean_absolute_error']))\n",
    "\n",
    "# appending metrics to df_summary\n",
    "scores(elastic_cci_scores)\n",
    "\n",
    "score_dict=write('elasticnet_cci', elastic_cci_scores)\n",
    "\n",
    "df_summary=df_summary.append(score_dict, ignore_index=True)\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T22:53:57.523147Z",
     "start_time": "2021-10-21T22:53:57.517744Z"
    }
   },
   "source": [
    "## ElasticNet(no cci_value) GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T19:26:52.583903Z",
     "start_time": "2021-11-01T19:26:15.146901Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "             estimator=Pipeline(steps=[('linear', ElasticNet())]),\n",
       "             param_grid={'linear__alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7,\n",
       "                                           0.8, 0.9, 1.0]},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create steps\n",
    "\n",
    "steps = [#('transform', column_transform),\n",
    "         ('linear',ElasticNet())]\n",
    "\n",
    "#instantiate pipeline object\n",
    "pipe = Pipeline(steps)\n",
    "\n",
    "# split df_train into test and train sets \n",
    "# Column Transform df_train before split\n",
    "Y = df_train['Weekly_Sales']\n",
    "X = df_train.drop(columns = ['Date','cci_value','Weekly_Sales'])\n",
    "Z = column_transform_no_cci.fit(df_train.drop(columns = ['Date','cci_value','Weekly_Sales']))\n",
    "\n",
    "\n",
    "# GridSearchCV parameters\n",
    "param_grid = {'linear__alpha':[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]}\n",
    "\n",
    "scoring = {'R2': 'r2_score', 'MAE': 'mean_absolute_error', 'MSE': 'mean_squared_error'}\n",
    "\n",
    "cv = TimeSeriesSplit(n_splits=5)\n",
    "# instantiate GridSearchCV object using pipeline, parameters dict\n",
    "elastic_grid_search = GridSearchCV(pipe, param_grid, cv=cv, return_train_score = True)\n",
    "elastic_grid_search.fit(Z.transform(X), Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T19:26:56.217879Z",
     "start_time": "2021-11-01T19:26:56.213979Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'linear__alpha': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: {}\".format(elastic_grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T19:28:21.834803Z",
     "start_time": "2021-11-01T19:27:03.085758Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.50384932e+08 -3.31721904e+08 -3.64080390e+08 -2.42577721e+08\n",
      " -2.60902714e+08]\n",
      "[0.24260747 0.30042102 0.23885641 0.2842203  0.29636956]\n",
      "[-15532.07167359 -12113.45382472 -14056.32962458 -10797.74866351\n",
      " -10928.57994587]\n"
     ]
    }
   ],
   "source": [
    "# cross validate gridsearchcv model\n",
    "# split df_train into test and train sets \n",
    "# Column Transform df_train before split\n",
    "Y = df_train['Weekly_Sales']\n",
    "X = df_train.drop(columns = ['Date','cci_value','Weekly_Sales'])\n",
    "Z = column_transform_no_cci.fit(df_train.drop(columns = ['Date','cci_value','Weekly_Sales']))\n",
    "\n",
    "cv = TimeSeriesSplit(n_splits=5)\n",
    "elastic_scores = cross_validate(elastic_grid_search, Z.transform(X), Y, cv=cv,\n",
    "                        scoring=('r2', 'neg_mean_squared_error', 'neg_mean_absolute_error'), n_jobs=-1)\n",
    "print(elastic_scores['test_neg_mean_squared_error'])\n",
    "print(elastic_scores['test_r2'])\n",
    "print(elastic_scores['test_neg_mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T19:28:26.811469Z",
     "start_time": "2021-11-01T19:28:26.787343Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>model description</th>\n",
       "      <th>test_neg_mean_absolute_error</th>\n",
       "      <th>test_neg_mean_squared_error</th>\n",
       "      <th>test_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>lr base no cci</td>\n",
       "      <td>1.907341e+13</td>\n",
       "      <td>1.298076e+27</td>\n",
       "      <td>1.931299e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>lr cci</td>\n",
       "      <td>4.162970e+12</td>\n",
       "      <td>3.802971e+25</td>\n",
       "      <td>8.225199e+16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>lr gridsearch</td>\n",
       "      <td>1.524266e+04</td>\n",
       "      <td>4.707473e+08</td>\n",
       "      <td>2.000000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>elasticnet_base</td>\n",
       "      <td>1.478978e+04</td>\n",
       "      <td>4.492629e+08</td>\n",
       "      <td>6.000000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>elasticnet_cci</td>\n",
       "      <td>1.478953e+04</td>\n",
       "      <td>4.492225e+08</td>\n",
       "      <td>6.000000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>elasticnet_gridsearch</td>\n",
       "      <td>1.268564e+04</td>\n",
       "      <td>3.499335e+08</td>\n",
       "      <td>2.700000e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name      model description  test_neg_mean_absolute_error  \\\n",
       "0   NaN         lr base no cci                  1.907341e+13   \n",
       "1   NaN                 lr cci                  4.162970e+12   \n",
       "2   NaN          lr gridsearch                  1.524266e+04   \n",
       "3   NaN        elasticnet_base                  1.478978e+04   \n",
       "4   NaN         elasticnet_cci                  1.478953e+04   \n",
       "5   NaN  elasticnet_gridsearch                  1.268564e+04   \n",
       "\n",
       "   test_neg_mean_squared_error       test_r2  \n",
       "0                 1.298076e+27  1.931299e+18  \n",
       "1                 3.802971e+25  8.225199e+16  \n",
       "2                 4.707473e+08  2.000000e-02  \n",
       "3                 4.492629e+08  6.000000e-02  \n",
       "4                 4.492225e+08  6.000000e-02  \n",
       "5                 3.499335e+08  2.700000e-01  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# appending metrics to df_summary\n",
    "scores(elastic_scores)\n",
    "\n",
    "score_dict=write('elasticnet_gridsearch', elastic_scores)\n",
    "\n",
    "df_summary=df_summary.append(score_dict, ignore_index=True)\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T17:30:40.470227Z",
     "start_time": "2021-10-28T17:30:40.144488Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>model description</th>\n",
       "      <th>test_neg_mean_absolute_error</th>\n",
       "      <th>test_neg_mean_squared_error</th>\n",
       "      <th>test_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>lr base no cci</td>\n",
       "      <td>4.699520e+14</td>\n",
       "      <td>1.237278e+30</td>\n",
       "      <td>1.708826e+21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>lr cci</td>\n",
       "      <td>3.743480e+14</td>\n",
       "      <td>8.155702e+29</td>\n",
       "      <td>1.124642e+21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>lr gridsearch</td>\n",
       "      <td>1.520359e+04</td>\n",
       "      <td>4.704408e+08</td>\n",
       "      <td>2.000000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>elasticnet_base</td>\n",
       "      <td>1.479865e+04</td>\n",
       "      <td>4.492972e+08</td>\n",
       "      <td>6.000000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>elasticnet_cci</td>\n",
       "      <td>1.479897e+04</td>\n",
       "      <td>4.492766e+08</td>\n",
       "      <td>6.000000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>elasticnet_gridsearch</td>\n",
       "      <td>1.268548e+04</td>\n",
       "      <td>3.498865e+08</td>\n",
       "      <td>2.700000e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name      model description  test_neg_mean_absolute_error  \\\n",
       "0   NaN         lr base no cci                  4.699520e+14   \n",
       "1   NaN                 lr cci                  3.743480e+14   \n",
       "2   NaN          lr gridsearch                  1.520359e+04   \n",
       "3   NaN        elasticnet_base                  1.479865e+04   \n",
       "4   NaN         elasticnet_cci                  1.479897e+04   \n",
       "5   NaN  elasticnet_gridsearch                  1.268548e+04   \n",
       "\n",
       "   test_neg_mean_squared_error       test_r2  \n",
       "0                 1.237278e+30  1.708826e+21  \n",
       "1                 8.155702e+29  1.124642e+21  \n",
       "2                 4.704408e+08  2.000000e-02  \n",
       "3                 4.492972e+08  6.000000e-02  \n",
       "4                 4.492766e+08  6.000000e-02  \n",
       "5                 3.498865e+08  2.700000e-01  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write df_summary to df_summary_linear file \n",
    "# df_summary_linear to be used for results discussion in Capstone 3 Modeling - Results Plots.ipynb\n",
    "\n",
    "df_summary.to_csv('df_summary_linear',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "316px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 391.734375,
   "position": {
    "height": "40px",
    "left": "68.171875px",
    "right": "20px",
    "top": "65px",
    "width": "652px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
